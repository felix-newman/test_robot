{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ACT Training - One Step Walkthrough\n",
    "\n",
    "This notebook demonstrates the training process for the Action Chunking Transformer (ACT) policy, stripped down to the absolute essentials. We will run a single training step on a CPU to understand the data flow, policy architecture, and loss calculation.\n",
    "\n",
    "We will covers:\n",
    "1.  **Configuration**: Setting up the minimal training and policy configs.\n",
    "2.  **Dataset**: Loading a real robotics dataset (`lerobot/pusht`).\n",
    "3.  **Policy**: Instantiating the ACT policy and its underlying model.\n",
    "4.  **Preprocessing**: Creating data processors for normalization.\n",
    "5.  **Training Step**: Running the forward pass, calculating loss, and updating weights.\n",
    "\n",
    "This is a simplified version of `lerobot/scripts/lerobot_train.py`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    }
   ],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "import torch\n",
    "from torch.utils.data import DataLoader\n",
    "from pathlib import Path\n",
    "import logging\n",
    "\n",
    "# LeRobot imports\n",
    "from lerobot.configs.train import TrainPipelineConfig, DatasetConfig\n",
    "from lerobot.policies.act.configuration_act import ACTConfig\n",
    "from lerobot.datasets.factory import make_dataset\n",
    "from lerobot.policies.factory import make_policy, make_pre_post_processors\n",
    "from lerobot.optim.factory import make_optimizer_and_scheduler\n",
    "from lerobot.utils.utils import init_logging\n",
    "from lerobot.optim.optimizers import AdamWConfig\n",
    "\n",
    "# Configure logging to see what's happening\n",
    "init_logging()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Configuration\n",
    "\n",
    "We need two main configurations:\n",
    "- `ACTConfig`: Defines the policy architecture (ResNet backbone, Transformer layers, VAE settings).\n",
    "- `TrainPipelineConfig`: Defines training parameters (batch size, dataset, optimizer).\n",
    "\n",
    "We'll use the `lerobot/pusht` dataset, a common benchmark for 2D manipulation.\n",
    "\n",
    "**Note**: We set `device='cpu'` for simplicity and compatibility in this notebook, but you should use 'cuda' for real training."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO 2025-11-26 12:05:18 ils/utils.py:43 Cuda backend detected, using cuda.\n",
      "WARNING 2025-11-26 12:05:18 /policies.py:82 Device 'None' is not available. Switching to 'cuda'.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Configuration ready.\n"
     ]
    }
   ],
   "source": [
    "# Define the Policy Configuration\n",
    "from lerobot.optim.optimizers import AdamWConfig\n",
    "\n",
    "\n",
    "policy_cfg = ACTConfig(\n",
    "    # Input/Output structure\n",
    "    n_obs_steps=1,\n",
    "    chunk_size=100,\n",
    "    n_action_steps=100,\n",
    "    # Architecture details\n",
    "    dim_model=512,\n",
    "    n_heads=8,\n",
    "    n_encoder_layers=4,\n",
    "    n_decoder_layers=1,\n",
    "    dropout=0.1,\n",
    "    # VAE settings\n",
    "    use_vae=True,\n",
    "    latent_dim=32,\n",
    "    # Vision Backbone\n",
    "    vision_backbone=\"resnet18\",\n",
    "    pretrained_backbone_weights=\"ResNet18_Weights.IMAGENET1K_V1\",\n",
    "    # Training settings\n",
    "    optimizer_lr=1e-5,\n",
    "    optimizer_weight_decay=1e-4,\n",
    "    kl_weight=10.0,\n",
    ")\n",
    "\n",
    "# Define the Dataset Configuration\n",
    "dataset_cfg = DatasetConfig(\n",
    "    repo_id=\"lerobot/pusht\",\n",
    "    root=\"data\",  # Local cache directory\n",
    "    revision=\"main\",\n",
    ")\n",
    "\n",
    "# Combine into the main Training Configuration\n",
    "cfg = TrainPipelineConfig(\n",
    "    dataset=dataset_cfg,\n",
    "    policy=policy_cfg,\n",
    "    batch_size=8,\n",
    "    num_workers=0,  # 0 for main process only (easier for debugging)\n",
    "    save_checkpoint=False,\n",
    "    steps=10,  # We only run 1 step manually\n",
    "    output_dir=Path(\"outputs/train/notebook_test\"),\n",
    "    optimizer=AdamWConfig(\n",
    "        lr=1e-5,\n",
    "        weight_decay=1e-4,\n",
    "        grad_clip_norm=10.0,\n",
    "    ),\n",
    ")\n",
    "\n",
    "print(\"Configuration ready.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Dataset Loading\n",
    "\n",
    "We use `make_dataset` to download (if needed) and prepare the dataset. `LeRobotDataset` handles synchronization between different modalities (images, robot states, actions) and calculates necessary statistics for normalization."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c44fcb1efafc4e14b5c468fe329036fb",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Fetching 4 files:   0%|          | 0/4 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2ccd0f4725454ef7b63aa8dd3aa3f561",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "info.json: 0.00B [00:00, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "54fd2386998e46158026d4b79817a2c0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "stats.json: 0.00B [00:00, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5af681197e6145eb869df11d70a8089d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "meta/episodes/chunk-000/file-000.parquet:   0%|          | 0.00/107k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0b7c7b0bdb164209850a250fd31124d6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "meta/tasks.parquet:   0%|          | 0.00/2.27k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5436fe30b8b749698650d22fd2ea0fe8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Fetching 8 files:   0%|          | 0/8 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2d31512a39474b4aaafb0b219b392939",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "README.md: 0.00B [00:00, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "50bc8e62feec41029bc732f61fdd7fb2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       ".gitattributes: 0.00B [00:00, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "52716719abce43e69848429ae7412cea",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "videos/observation.image/chunk-000/file-(â€¦):   0%|          | 0.00/6.89M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "355a4d00249a45a7a2cdf4eb20a1cdfe",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "data/chunk-000/file-000.parquet:   0%|          | 0.00/674k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset loaded: lerobot/pusht\n",
      "Number of episodes: 206\n",
      "Number of frames: 25650\n",
      "Features: dict_keys(['observation.image', 'observation.state', 'action', 'episode_index', 'frame_index', 'timestamp', 'next.reward', 'next.done', 'next.success', 'index', 'task_index'])\n",
      "Stats keys: dict_keys(['index', 'next.success', 'observation.state', 'next.done', 'observation.image', 'timestamp', 'episode_index', 'frame_index', 'action', 'task_index', 'next.reward'])\n"
     ]
    }
   ],
   "source": [
    "# Create the dataset\n",
    "dataset = make_dataset(cfg)\n",
    "\n",
    "print(f\"Dataset loaded: {dataset.repo_id}\")\n",
    "print(f\"Number of episodes: {dataset.num_episodes}\")\n",
    "print(f\"Number of frames: {dataset.num_frames}\")\n",
    "print(f\"Features: {dataset.features.keys()}\")\n",
    "\n",
    "# We can check the statistics (mean/std) computed from the dataset\n",
    "# These will be used by the policy to normalize inputs\n",
    "stats = dataset.meta.stats\n",
    "print(\"Stats keys:\", stats.keys())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Policy Initialization\n",
    "\n",
    "`make_policy` initializes the ACT policy. It infers input/output shapes from the dataset metadata. The policy contains:\n",
    "- **Backbone**: ResNet18 for processing images.\n",
    "- **VAE Encoder**: Encodes action sequences into a latent space (during training).\n",
    "- **Transformer Encoder/Decoder**: Predicts action chunks from observations and latent z.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Policy initialized: act\n",
      "Policy moved to cuda\n"
     ]
    }
   ],
   "source": [
    "policy = make_policy(\n",
    "    cfg=cfg.policy,\n",
    "    ds_meta=dataset.meta,\n",
    ")\n",
    "\n",
    "print(\"Policy initialized:\", policy.name)\n",
    "# Move to device (CPU for this demo, use 'cuda' if available)\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "policy.to(device)\n",
    "print(f\"Policy moved to {device}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Preprocessing and Optimization\n",
    "\n",
    "We need:\n",
    "1.  **Processors**: To normalize raw data (images [0-255] -> [0-1], vectors -> mean 0 std 1).\n",
    "2.  **Optimizer**: AdamW is standard for Transformers.\n",
    "3.  **DataLoader**: Pytorch's standard data loader."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pipeline components ready.\n"
     ]
    }
   ],
   "source": [
    "# 1. Create Pre- and Post-processors\n",
    "# These handle normalization using the dataset statistics we saw earlier\n",
    "preprocessor, postprocessor = make_pre_post_processors(\n",
    "    policy_cfg=cfg.policy, dataset_stats=dataset.meta.stats\n",
    ")\n",
    "\n",
    "# 2. Create Optimizer\n",
    "optimizer, lr_scheduler = make_optimizer_and_scheduler(cfg, policy)\n",
    "\n",
    "# 3. Create DataLoader\n",
    "dataloader = DataLoader(\n",
    "    dataset,\n",
    "    num_workers=cfg.num_workers,\n",
    "    batch_size=cfg.batch_size,\n",
    "    shuffle=True,\n",
    "    drop_last=False,\n",
    ")\n",
    "\n",
    "print(\"Pipeline components ready.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. The Training Step\n",
    "\n",
    "Now we perform a single training iteration manually. This corresponds to the `update_policy` function in `lerobot_train.py`.\n",
    "\n",
    "**The Flow:**\n",
    "1.  **Fetch Batch**: Get a dictionary of tensors (images, states, actions) from the dataloader.\n",
    "2.  **Preprocess**: Normalize the batch (on CPU).\n",
    "3.  **Move to Device**: Send data to GPU/CPU.\n",
    "4.  **Forward Pass**: `policy(batch)` computes the loss.\n",
    "    -   ACT uses a VAE objective: `loss = reconstruction_loss + kl_weight * kld_loss`.\n",
    "    -   It tries to reconstruct the `action` chunk given the `observation` and the `latent`.\n",
    "5.  **Backward Pass**: Compute gradients.\n",
    "6.  **Optimizer Step**: Update model weights."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Raw batch keys: dict_keys(['observation.image', 'observation.state', 'action', 'episode_index', 'frame_index', 'timestamp', 'next.reward', 'next.done', 'next.success', 'index', 'task_index', 'action_is_pad', 'task'])\n",
      "\n",
      "--- Training Step Results ---\n",
      "Total Loss: 66.0094\n",
      "Component Losses: {'l1_loss': 0.7924197912216187, 'kld_loss': 6.521697044372559}\n",
      "Gradient Norm: 1103.7797\n",
      "Weights updated successfully!\n"
     ]
    }
   ],
   "source": [
    "# 1. Fetch a single batch\n",
    "dl_iter = iter(dataloader)\n",
    "batch = next(dl_iter)\n",
    "print(\"Raw batch keys:\", batch.keys())\n",
    "\n",
    "# 2. Preprocess (Normalization)\n",
    "# Note: The preprocessor expects data on CPU usually, but handles device internally if configured.\n",
    "batch = preprocessor(batch)\n",
    "\n",
    "# 3. Move batch to device\n",
    "for key in batch:\n",
    "    if isinstance(batch[key], torch.Tensor):\n",
    "        batch[key] = batch[key].to(device)\n",
    "\n",
    "# Set policy to training mode\n",
    "policy.train()\n",
    "\n",
    "# 4. Forward Pass\n",
    "# The policy.forward() method handles the complex logic of the ACT model:\n",
    "# - Encoding images with ResNet\n",
    "# - Encoding action sequence with VAE encoder (to get z)\n",
    "# - decoding with Transformer\n",
    "# - Computing L1 loss (action reconstruction) and KL loss (VAE regularization)\n",
    "loss, output_dict = policy.forward(batch)\n",
    "\n",
    "print(\"\\n--- Training Step Results ---\")\n",
    "print(f\"Total Loss: {loss.item():.4f}\")\n",
    "print(\"Component Losses:\", output_dict)\n",
    "\n",
    "# 5. Backward Pass\n",
    "optimizer.zero_grad()\n",
    "loss.backward()\n",
    "\n",
    "# Clip gradients (standard practice for Transformers)\n",
    "grad_norm = torch.nn.utils.clip_grad_norm_(\n",
    "    policy.parameters(), cfg.optimizer.grad_clip_norm\n",
    ")\n",
    "print(f\"Gradient Norm: {grad_norm.item():.4f}\")\n",
    "\n",
    "# 6. Optimizer Step\n",
    "optimizer.step()\n",
    "\n",
    "print(\"Weights updated successfully!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Conclusion\n",
    "\n",
    "You've successfully run one step of ACT training! \n",
    "\n",
    "**Key Takeaways:**\n",
    "- The `make_dataset` and `make_policy` helpers simplify initialization significantly.\n",
    "- `preprocessor` is critical; the model expects normalized inputs.\n",
    "- The policy's `forward` method encapsulates the specific algorithm logic (ACT's VAE + Transformer), returning a ready-to-optimize loss.\n",
    "\n",
    "In the full training script, this loop repeats for thousands of steps, with added logic for:\n",
    "- Checkpointing (saving the model).\n",
    "- Evaluation (running the policy in a simulation/real robot).\n",
    "- Logging (WandB).\n",
    "- Distributed training (multi-GPU)."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
